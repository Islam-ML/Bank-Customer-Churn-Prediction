# ðŸ¦ Bank Customer Churn Prediction

## ðŸ“– Project Overview | Ù†Ø¨Ø°Ø© Ø¹Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

**[English]**
Customer churn is a critical metric for banking institutions. This project aims to build a robust Machine Learning model to predict whether a customer will leave the bank based on their demographic and financial data. By identifying at-risk customers early, the bank can implement retention strategies to reduce losses.

**[Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©]**
ØªØ¹ØªØ¨Ø± Ù…ØºØ§Ø¯Ø±Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ (Churn) Ù…Ù† Ø£Ù‡Ù… Ø§Ù„ØªØ­Ø¯ÙŠØ§Øª Ø§Ù„ØªÙŠ ØªÙˆØ§Ø¬Ù‡ Ø§Ù„Ù…Ø¤Ø³Ø³Ø§Øª Ø§Ù„Ø¨Ù†ÙƒÙŠØ©. ÙŠÙ‡Ø¯Ù Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¥Ù„Ù‰ Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø¢Ù„ÙŠ Ù‚ÙˆÙŠ Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø³ÙŠØªØ±Ùƒ Ø§Ù„Ø¨Ù†Ùƒ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§ØªÙ‡ Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠØ© ÙˆØ§Ù„Ù…Ø§Ù„ÙŠØ©. ÙŠØ³Ø§Ø¹Ø¯ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¨Ù†Ùƒ Ø¹Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø±Ø¶ÙŠÙ† Ù„Ù„Ù…ØºØ§Ø¯Ø±Ø© ÙˆØ§ØªØ®Ø§Ø° Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ø³ØªØ¨Ø§Ù‚ÙŠØ© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„ÙŠÙ‡Ù….

---

## ðŸ› ï¸ Tech Stack | Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØ§Ù„ØªÙ‚Ù†ÙŠØ§Øª

The project utilizes a comprehensive stack of Data Science tools:

*   **Data Manipulation:** `Pandas`, `NumPy`
*   **Visualization:** `Matplotlib`, `Seaborn`
*   **Machine Learning:** `Scikit-Learn`, `XGBoost`, `SVM`, `Random Forest`
*   **Deep Learning:** `TensorFlow / Keras (ANN)`
*   **Imbalance Handling:** `SMOTE` (Synthetic Minority Over-sampling Technique)

---

## ðŸ“Š Methodology | Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„Ø¹Ù…Ù„

1.  **Exploratory Data Analysis (EDA):** Analyzing feature distributions and correlations (Heatmaps) to understand churn drivers.
2.  **Data Preprocessing:**
    *   Handling missing values (if any).
    *   **One-Hot Encoding** for categorical features (Geography, Gender).
    *   **Feature Scaling** using `StandardScaler`.
3.  **Model Development:** Training and evaluating 5 different models.
4.  **Handling Class Imbalance:** Applying **SMOTE** to improve recall for the minority class (Churners).
5.  **Evaluation:** Comparing models based on Accuracy, Precision, Recall, and F1-Score.

---

## ðŸ† Model Performance & Results | Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡

After extensive experimentation, we compared the models' performance on the test set. The **XGBoost Classifier** proved to be the most balanced model.

| Model | Accuracy | Precision (Class 1) | Recall (Class 1) | Verdict |
| :--- | :---: | :---: | :---: | :--- |
| **XGBoost (Winner)** ðŸ¥‡ | **86.95%** | **High** | **Balanced** | **Best Overall Performance** |
| Random Forest | 86.65% | High | Moderate | Strong Contender |
| ANN (Deep Learning) | 86.30% | Moderate | Moderate | Good Baseline |
| SVM | 85.60% | High | Low | Good Precision, Low Recall |
| Logistic Regression | 81.10% | Low | Low | Underperformed |

> **Note:** While applying **SMOTE** significantly increased the *Recall* (ability to find churners), it slightly reduced the overall *Accuracy*. The standard XGBoost model offered the best trade-off for this specific business case.

---

## ðŸ“ˆ Visualizations | Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ©

*(You can add screenshots of your plots here, e.g., Correlation Heatmap or XGBoost Learning Curve)*

*   **Correlation Heatmap:** To show relationships between features.
*   **XGBoost Learning Curve:** Demonstrating the reduction of Log Loss over training rounds.
